{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Step 1 - Reading Images and Preparing samples'''\n",
    "\n",
    "import csv\n",
    "\n",
    "# Dictionaries to save all 10 folds of positive and negative samples\n",
    "positive_samples = {}\n",
    "negative_samples = {}\n",
    "\n",
    "# Read txt file for negative and positive pairs in the dataset\n",
    "with open('../data/pairs.txt', newline = '') as pairs:  \n",
    "    \n",
    "    pair_reader = csv.reader(pairs, delimiter='\\t')\n",
    "    sample_size = next(pair_reader)\n",
    "    \n",
    "    number_of_folds = int(sample_size[0])\n",
    "    fold_size = int(sample_size[1])\n",
    "    \n",
    "    for fold in range(number_of_folds):\n",
    "        \n",
    "        positive_samples[fold] = []\n",
    "        negative_samples[fold] = []\n",
    "        \n",
    "        # Create list of filenames for all positive pairs\n",
    "        for i in range(fold_size):\n",
    "            pair = next(pair_reader)\n",
    "            positive_samples[fold].append([pair[0] + '/' + pair[0] + '_' + '0'*(4-len(pair[1])) + pair[1],\n",
    "                                     pair[0] + '/' + pair[0] + '_' + '0'*(4-len(pair[2])) + pair[2]])\n",
    "        \n",
    "        # Create list of filenames for all negative pairs\n",
    "        for i in range(fold_size):\n",
    "            pair = next(pair_reader)\n",
    "            negative_samples[fold].append([pair[0] + '/' + pair[0] + '_' + '0'*(4-len(pair[1])) + pair[1],\n",
    "                                     pair[2] + '/' + pair[2] + '_' + '0'*(4-len(pair[3])) + pair[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Function - Dlib library for finding embeddings from images'''\n",
    "\n",
    "import dlib\n",
    "\n",
    "predictor_path = \"../model/shape_predictor_5_face_landmarks.dat\"\n",
    "face_rec_model_path = \"../model/dlib_face_recognition_resnet_model_v1.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "sp = dlib.shape_predictor(predictor_path)\n",
    "facerec = dlib.face_recognition_model_v1(face_rec_model_path)\n",
    "\n",
    "def extract_embeddings(f):\n",
    "    img = dlib.load_rgb_image(f)\n",
    "    # get bounding box for the face in image\n",
    "    result = detector(img, 1)\n",
    "    #For the assignment we are assuming that each image has only 1 face detected\n",
    "    d=result[0]\n",
    "    shape = sp(img, d)\n",
    "    # Compute the 128D vector that describes the face in img\n",
    "    face_descriptor = facerec.compute_face_descriptor(img, shape)\n",
    "    return(face_descriptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' Step 2 - Changing the images into embeddings and saving them respectively in positive_emb \n",
    "and negative_emb dictionary'''\n",
    "\n",
    "positive_emb = {}\n",
    "negative_emb = {}\n",
    "y = {}\n",
    "\n",
    "# Get emeddings for all 10 folds\n",
    "for fold in range(number_of_folds):\n",
    "    \n",
    "    y[fold] = [] # gererate y label along with embeddings\n",
    "    positive_emb[fold] = []\n",
    "    \n",
    "    # save embeddings for positive samples in each fold\n",
    "    for pairs in positive_samples[fold]:\n",
    "        try:\n",
    "            emb1 = extract_embeddings('../data/lfw/' + pairs[0] + '.jpg')\n",
    "            emb2 = extract_embeddings('../data/lfw/' + pairs[1] + '.jpg')\n",
    "\n",
    "            # convert dlib.vector to array for ease in manipulation\n",
    "            positive_emb[fold].append([np.array(emb1),np.array(emb2)])\n",
    "            y[fold].append(1)\n",
    "\n",
    "        except:\n",
    "            print(str(pairs) + ' Not resolved')\n",
    "\n",
    "    # save embeddings for negative samples in each fold\n",
    "    negative_emb[fold] = []\n",
    "    for pairs in negative_samples[fold]:\n",
    "        try:\n",
    "            emb1 = extract_embeddings('../data/lfw/' + pairs[0] + '.jpg')\n",
    "            emb2 = extract_embeddings('../data/lfw/' + pairs[1] + '.jpg')\n",
    "\n",
    "            # convert dlib.vector to array for ease in manipulation\n",
    "            negative_emb[fold].append([np.array(emb1),np.array(emb2)])\n",
    "            y[fold].append(0)\n",
    "\n",
    "        except:\n",
    "            print(str(pairs) + ' Not resolved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Step 3 - Finding L2 distance between the embeddings'''\n",
    "\n",
    "X_d = {}\n",
    "\n",
    "for fold in range(number_of_folds):\n",
    "    X_d[fold] = []\n",
    "    for emb in positive_emb[fold]:\n",
    "        X_d[fold].append(np.linalg.norm(emb[0] - emb[1]))\n",
    "\n",
    "    for emb in negative_emb[fold]:\n",
    "        X_d[fold].append(np.linalg.norm(emb[0] - emb[1]))\n",
    "\n",
    "    X_d[fold] = np.expand_dims(np.array(X_d[fold]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Step 4 - Preparing inputs for difference in embeddings based logistic regression model''' \n",
    "\n",
    "X = {}\n",
    "\n",
    "for fold in range(number_of_folds):\n",
    "    X[fold] = np.empty((len(y[fold]),128))\n",
    "    for emb in positive_emb[fold]:\n",
    "        np.append(X[fold],emb[0] - emb[1])\n",
    "\n",
    "    for emb in negative_emb[fold]:\n",
    "        np.append(X[fold],emb[0] - emb[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Step 5 -  Model 1 - Create the Logistic Regression model which takes input as the distance \n",
    "between the embeddings of two images and outputs the similarity score(probablity) and \n",
    "prediction (binary yes/no) between the two images'''\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "logreg_dist = LogisticRegression()\n",
    "scores_list = []\n",
    "for fold in range(number_of_folds):\n",
    "    scores = cross_val_score(logreg_dist, X_d[fold], y[fold], cv=5, scoring = 'accuracy')\n",
    "    scores_list.append(scores.mean())\n",
    "    \n",
    "sum(scores_list)/len(scores_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Step 6 -  Model 2 - Create the Logistic Regression model which takes input as the \n",
    "difference between the each field of the embeddings of two images and outputs the similarity \n",
    "score(probablity) and prediction (binary yes/no) between the two images'''\n",
    "\n",
    "logreg_emb = LogisticRegression()\n",
    "scores_list = []\n",
    "for fold in range(number_of_folds):\n",
    "    scores = cross_val_score(logreg_emb, X[fold], y[fold], cv=5, scoring = 'accuracy')\n",
    "    scores_list.append(scores.mean())\n",
    "    \n",
    "sum(scores_list)/len(scores_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
