{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Step 1 - Reading Images and Preparing samples'''\n",
    "\n",
    "import csv\n",
    "\n",
    "# Dictionaries to save all 10 folds of positive and negative samples\n",
    "positive_samples = {}\n",
    "negative_samples = {}\n",
    "\n",
    "# Read txt file for negative and positive pairs in the dataset\n",
    "with open('../data/pairs.txt', newline = '') as pairs:  \n",
    "    \n",
    "    pair_reader = csv.reader(pairs, delimiter='\\t')\n",
    "    sample_size = next(pair_reader)\n",
    "    \n",
    "    number_of_folds = int(sample_size[0])\n",
    "    fold_size = int(sample_size[1])\n",
    "    \n",
    "    for fold in range(number_of_folds):\n",
    "        \n",
    "        positive_samples[fold] = []\n",
    "        negative_samples[fold] = []\n",
    "        \n",
    "        # Create list of filenames for all positive pairs\n",
    "        for i in range(fold_size):\n",
    "            pair = next(pair_reader)\n",
    "            positive_samples[fold].append([pair[0] + '/' + pair[0] + '_' + '0'*(4-len(pair[1])) + pair[1],\n",
    "                                     pair[0] + '/' + pair[0] + '_' + '0'*(4-len(pair[2])) + pair[2]])\n",
    "        \n",
    "        # Create list of filenames for all negative pairs\n",
    "        for i in range(fold_size):\n",
    "            pair = next(pair_reader)\n",
    "            negative_samples[fold].append([pair[0] + '/' + pair[0] + '_' + '0'*(4-len(pair[1])) + pair[1],\n",
    "                                     pair[2] + '/' + pair[2] + '_' + '0'*(4-len(pair[3])) + pair[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Pretrained model - load facenet model from keras'''\n",
    "\n",
    "from keras.models import load_model\n",
    "model = load_model(\"../model/facenet_keras.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Function - Dlib library for finding embeddings from images'''\n",
    "\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "\n",
    "# function to get embeddings for an image\n",
    "def extract_embeddings(filename, image_size, model):\n",
    "\n",
    "    image = Image.open(filename)\n",
    "    pixels = asarray(image)\n",
    "\n",
    "    # detect bounding box around the face from image using mtncc\n",
    "    detector = MTCNN()\n",
    "    results = detector.detect_faces(pixels)\n",
    "\n",
    "    # Cropping face out of image using the detected bounding box\n",
    "    x1, y1, width, height = results[0]['box']\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    face = pixels[y1:y1 + height, x1:x1 + width]\n",
    "\n",
    "    # Converting image data to a format readable by our model(facenet model) to get embeddings\n",
    "    img = Image.fromarray(face)\n",
    "    img = img.resize(image_size)\n",
    "    face_crop = asarray(img)\n",
    "    face_crop = face_crop.astype('float32')\n",
    "    mean, std = face_crop.mean(), face_crop.std()\n",
    "    face_crop = (face_crop - mean) / std\n",
    "    samples = np.expand_dims(face_crop, axis=0)\n",
    "\n",
    "    # Get embeddings\n",
    "    embedding = model.predict(samples)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "''' Step 2 - Changing the images into embeddings and saving them respectively in positive_emb \n",
    "and negative_emb dictionary'''\n",
    "\n",
    "total_samples = 20\n",
    "\n",
    "# Get emeddings for desired number(upto 300) of positive pairs\n",
    "# using only samples from fold 1 since getting embeddings for all folds took lot of time\n",
    "positive_emb = []\n",
    "for pairs in positive_samples[0][:total_samples]:\n",
    "    print('resolving ' + str(pairs))\n",
    "    emb1 = extract_embeddings('../data/lfw/' + pairs[0] + '.jpg', (160,160), model)\n",
    "    emb2 = extract_embeddings('../data/lfw/' + pairs[1] + '.jpg', (160,160), model)\n",
    "\n",
    "    positive_emb.append([emb1,emb2])\n",
    "\n",
    "# Get emeddings for desired number(upto 300) of positive pairs\n",
    "negative_emb = []\n",
    "for pairs in negative_samples[0][:total_samples]:\n",
    "    print('resolving ' + str(pairs))\n",
    "    emb1 = extract_embeddings('../data/lfw/' + pairs[0] + '.jpg', (160,160), model)\n",
    "    emb2 = extract_embeddings('../data/lfw/' + pairs[1] + '.jpg', (160,160), model)\n",
    "\n",
    "    negative_emb.append([emb1,emb2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Step 3 - Finding L2 distance between the embeddings'''\n",
    "\n",
    "X_d = []\n",
    "for emb in positive_emb:\n",
    "    X_d.append(np.linalg.norm(emb[0] - emb[1]))\n",
    "    \n",
    "for emb in negative_emb:\n",
    "    X_d.append(np.linalg.norm(emb[0] - emb[1]))\n",
    "    \n",
    "X_d = np.expand_dims(np.array(X_d),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Step 4 - Preparing inputs for difference in embeddings based logistic regression model''' \n",
    "\n",
    "X = np.empty((total_samples*2,128))\n",
    "for emb in positive_emb:\n",
    "    np.append(X,emb[0] - emb[1])\n",
    "    \n",
    "for emb in negative_emb:\n",
    "    np.append(X,emb[0] - emb[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Step 5 - Prepare target variable'''\n",
    "y = np.append(np.ones((total_samples,1)),np.zeros((total_samples,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Step 6 -  Model 1 - Create the Logistic Regression model which takes input as the distance \n",
    "between the embeddings of two images and outputs the similarity score(probablity) and \n",
    "prediction (binary yes/no) between the two images'''\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "logreg_dist = LogisticRegression()\n",
    "scores = cross_val_score(logreg_dist, X_d, y, cv=5, scoring = 'accuracy')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Step 7 -  Model 2 - Create the Logistic Regression model which takes input as the \n",
    "difference between the each field of the embeddings of two images and outputs the similarity \n",
    "score(probablity) and prediction (binary yes/no) between the two images'''\n",
    "\n",
    "logreg_emb = LogisticRegression()\n",
    "scores = cross_val_score(logreg_emb, X, y, cv=5, scoring = 'accuracy')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
